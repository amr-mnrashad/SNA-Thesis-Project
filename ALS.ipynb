{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lodaing The Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import coo_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Community_Label</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>PR_Community</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>8/31/2022</td>\n",
       "      <td>Lost-My-Mind-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>8/31/2022</td>\n",
       "      <td>SgtDoughnut</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>8/31/2022</td>\n",
       "      <td>JasonDJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>8/31/2022</td>\n",
       "      <td>tacknosaddle</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>8/31/2022</td>\n",
       "      <td>jezra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subreddit       Date        User_ID  Community_Label  PageRank  \\\n",
       "0  AdviceAnimals  8/31/2022  Lost-My-Mind-                0  0.000407   \n",
       "1  AdviceAnimals  8/31/2022    SgtDoughnut                0  0.000137   \n",
       "2  AdviceAnimals  8/31/2022        JasonDJ                0  0.000082   \n",
       "3  AdviceAnimals  8/31/2022   tacknosaddle                0  0.000199   \n",
       "4  AdviceAnimals  8/31/2022          jezra                0  0.000081   \n",
       "\n",
       "   PR_Community Category  \n",
       "0      0.001599    Humor  \n",
       "1      0.000528    Humor  \n",
       "2      0.000312    Humor  \n",
       "3      0.000771    Humor  \n",
       "4      0.000309    Humor  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'overall_df.csv'\n",
    "overall_df = pd.read_csv(filename)\n",
    "overall_df = overall_df.drop(columns=['Population', 'Post_Title', 'Upvotes'])\n",
    "overall_df.rename(columns={'PageRank_Within_Community': 'PR_Community'}, inplace=True)\n",
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating List Of Community Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The aim of this section is to create a list of dataframes, where each dataframe represent a specific community. The reason behind doing this is: The collaborative filtering process will be focused on each community seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_community_dataframes(df):\n",
    "  community_dataframes = []\n",
    "\n",
    "  # Grouping the nodes_df by the 'Community_Library' column\n",
    "  grouped = df.groupby('Community_Label')\n",
    "\n",
    "  # Iterating through each community and create separate DataFrames\n",
    "  for community_id, community_nodes_df in grouped:\n",
    "      # Removing the 'Community_Library' column from the DataFrame, as it's no longer needed\n",
    "      community_nodes_df = community_nodes_df.drop(columns=['Community_Label'])\n",
    "\n",
    "      # Appending the DataFrame to the list\n",
    "      community_dataframes.append(community_nodes_df)\n",
    "\n",
    "  return community_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Community X DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>PR_Community</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25616</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25618</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25634</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25941</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Subreddit       Date  User_ID  PageRank  PR_Community  \\\n",
       "25616  AnimalsBeingDerps 2022-09-02  Sniflix   0.00018      0.002661   \n",
       "25618  AnimalsBeingDerps 2022-07-09  Sniflix   0.00018      0.002661   \n",
       "25634  AnimalsBeingDerps 2023-03-26  Sniflix   0.00018      0.002661   \n",
       "25700  AnimalsBeingDerps 2023-03-20  Sniflix   0.00018      0.002661   \n",
       "25941  AnimalsBeingDerps 2022-08-08  Sniflix   0.00018      0.002661   \n",
       "\n",
       "               Category  \n",
       "25616  Animals and Pets  \n",
       "25618  Animals and Pets  \n",
       "25634  Animals and Pets  \n",
       "25700  Animals and Pets  \n",
       "25941  Animals and Pets  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_dfs = create_community_dataframes(overall_df)\n",
    "for df in community_dfs:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Printing the first few nodes of a selected community DataFrame\n",
    "print(\"\\nCommunity X DataFrame:\")\n",
    "community_dfs[9].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The aim of this section I start figuring out how can I create a score/rate that best describes the user preference regarding a given subreddit.\n",
    "- I first compute the weights of the following subreddit and category. Each one describes the following: On average how many categories/subreddits does a user view.\n",
    "- I then compute the partial scores, which are engagement score for subreddit and for category. These partial scores describe or give more importance to the subreddits/categories that have been interacted with more by the user. For example if the user have performed an interaction in a subreddit X four times and in subreddit Y 2 times, then I give more importance to subreddit X than subreddit Y.  \n",
    "- Finally, I compute the decay factor, where I give more importance to a subreddit that has been interacted with several times in a day by a given user than a product that has been viewed several times but across several days that are far apart by the same user. The time decay factor was calculated by followaing the log approach, in order to give importance to reecency of the view date. For instance if user x has viewed product y today and yesterday the value of the decay factor won't be the same as when user x viewed product y today and 3 months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subreddit_weight(df):\n",
    "    # Grouping by 'User_ID' and count distinct 'Subreddit'\n",
    "    grouped = df.groupby('User_ID')['Subreddit'].nunique()\n",
    "    average_count = grouped.mean()\n",
    "    return average_count\n",
    "\n",
    "def calculate_category_weight(df):\n",
    "    # Grouping by 'User_ID' and count distinct 'Category'\n",
    "    grouped = df.groupby('User_ID')['Category'].nunique()\n",
    "    average_count = grouped.mean()\n",
    "    return average_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_interaction_ratio_subreddit(df):\n",
    "    subreddit_interactions = df.groupby(['User_ID', 'Subreddit']).size().reset_index(name='interactions')\n",
    "    total_interactions = df.groupby('User_ID').size().reset_index(name='total_interactions')\n",
    "\n",
    "    df = df.merge(subreddit_interactions, on=['User_ID', 'Subreddit'], how='left')\n",
    "    df = df.merge(total_interactions, on='User_ID', how='left')\n",
    "\n",
    "    df['Engagement_Score_Subreddit'] = df['interactions'] / df['total_interactions']\n",
    "    df = df.drop(['interactions', 'total_interactions'], axis=1)\n",
    "    return df\n",
    "\n",
    "def calculate_interaction_ratio_category(df):\n",
    "    category_interactions = df.groupby(['User_ID', 'Category']).size().reset_index(name='interactions')\n",
    "    total_interactions = df.groupby('User_ID').size().reset_index(name='total_interactions')\n",
    "\n",
    "    df = df.merge(category_interactions, on=['User_ID', 'Category'], how='left')\n",
    "    df = df.merge(total_interactions, on='User_ID', how='left')\n",
    "\n",
    "    df['Engagement_Score_Category'] = df['interactions'] / df['total_interactions']\n",
    "    df = df.drop(['interactions', 'total_interactions'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_date(df):\n",
    "    # Calculating the maximum date for each user-product combination\n",
    "    max_date_df = df.groupby(['User_ID', 'Subreddit'])['Date'].max().reset_index()\n",
    "    max_date_df.rename(columns={'Date': 'Last_Interaction_Date'}, inplace=True)\n",
    "\n",
    "    # Joining the max_date_df with the original df\n",
    "    df_with_max_date = df.merge(max_date_df, on=['User_ID', 'Subreddit'])\n",
    "    return df_with_max_date\n",
    "\n",
    "def calculate_decay_factor(row):\n",
    "    half_life_days = 7\n",
    "    days_diff = abs((pd.to_datetime(row['Date']) - pd.to_datetime(row['Last_Interaction_Date'])).days)\n",
    "    if days_diff == 0:\n",
    "        return 1\n",
    "    return 1 / np.log1p(1 + (days_diff / half_life_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_weight = []\n",
    "for df in community_dfs:\n",
    "    subreddit_weight.append(calculate_subreddit_weight(df))\n",
    "\n",
    "category_weight = []\n",
    "for df in community_dfs:\n",
    "    category_weight.append(calculate_category_weight(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dfs_1 = []\n",
    "for df in community_dfs:\n",
    "    temp_dfs_1.append(calculate_interaction_ratio_subreddit(df))\n",
    "\n",
    "temp_dfs_2 = []\n",
    "for df in temp_dfs_1:\n",
    "    temp_dfs_2.append(calculate_interaction_ratio_category(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>PR_Community</th>\n",
       "      <th>Category</th>\n",
       "      <th>Engagement_Score_Subreddit</th>\n",
       "      <th>Engagement_Score_Category</th>\n",
       "      <th>Last_Interaction_Date</th>\n",
       "      <th>Decay_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.264485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.253438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.373265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.365468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.259119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subreddit       Date  User_ID  PageRank  PR_Community  \\\n",
       "0  AnimalsBeingDerps 2022-09-02  Sniflix   0.00018      0.002661   \n",
       "1  AnimalsBeingDerps 2022-07-09  Sniflix   0.00018      0.002661   \n",
       "2  AnimalsBeingDerps 2023-03-26  Sniflix   0.00018      0.002661   \n",
       "3  AnimalsBeingDerps 2023-03-20  Sniflix   0.00018      0.002661   \n",
       "4  AnimalsBeingDerps 2022-08-08  Sniflix   0.00018      0.002661   \n",
       "\n",
       "           Category  Engagement_Score_Subreddit  Engagement_Score_Category  \\\n",
       "0  Animals and Pets                        0.42                       0.42   \n",
       "1  Animals and Pets                        0.42                       0.42   \n",
       "2  Animals and Pets                        0.42                       0.42   \n",
       "3  Animals and Pets                        0.42                       0.42   \n",
       "4  Animals and Pets                        0.42                       0.42   \n",
       "\n",
       "  Last_Interaction_Date  Decay_Factor  \n",
       "0            2023-06-22      0.264485  \n",
       "1            2023-06-22      0.253438  \n",
       "2            2023-06-22      0.373265  \n",
       "3            2023-06-22      0.365468  \n",
       "4            2023-06-22      0.259119  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date_dfs = []\n",
    "for df in temp_dfs_2:\n",
    "    max_date_dfs.append(max_date(df))\n",
    "for df in max_date_dfs:    \n",
    "    df['Decay_Factor'] = df.apply(calculate_decay_factor, axis=1)\n",
    "overall_dfs = max_date_dfs.copy()\n",
    "overall_dfs[9].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section I compute the implicit score by firstly computing the following equation: (subreddit weight * engagement score subreddit + category weight * engagement score category)*decay factor. The result of this equation is then used to compute the actual implicit score by integrating the pagerank score. Alpha is a parameter that controls the balance between the Total_Score and the PageRank scores. Higher alpha gives more weight to pagerank scores, making the recommendations more influenced by user importance in the community. I then compute the lower and upper bounds based on the interquartile range (IQR) and capping the Implicit_Score values that fall outside these bounds. This helps in mitigating the impact of outliers on your recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_implicit_score(df, subreddit_weight, category_weight, alpha):\n",
    "    df['Total_Score'] = (subreddit_weight * df['Engagement_Score_Subreddit'] + category_weight * df['Engagement_Score_Category'])* df['Decay_Factor']\n",
    "    df['Implicit_Score'] = (1 - alpha) * df['Total_Score'] + alpha * df['PR_Community']\n",
    "    lower_quartile = df['Implicit_Score'].quantile(0.25)\n",
    "    upper_quartile = df['Implicit_Score'].quantile(0.75)\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "\n",
    "    # Calculating lower and upper bounds\n",
    "    lower_bound = lower_quartile - 1.5 * iqr\n",
    "    upper_bound = upper_quartile + 1.5 * iqr\n",
    "\n",
    "    # Setting scores below lower bound to lower bound, and scores above upper bound to upper bound\n",
    "    df['Implicit_Score'] = df['Implicit_Score'].apply(lambda x: lower_bound if x < lower_bound else x)\n",
    "    df['Implicit_Score'] = df['Implicit_Score'].apply(lambda x: upper_bound if x > upper_bound else x)\n",
    "    final_df = df.copy()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>PR_Community</th>\n",
       "      <th>Category</th>\n",
       "      <th>Engagement_Score_Subreddit</th>\n",
       "      <th>Engagement_Score_Category</th>\n",
       "      <th>Last_Interaction_Date</th>\n",
       "      <th>Decay_Factor</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Implicit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.264485</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.079254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.253438</td>\n",
       "      <td>0.230005</td>\n",
       "      <td>0.079254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.373265</td>\n",
       "      <td>0.338752</td>\n",
       "      <td>0.103489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.365468</td>\n",
       "      <td>0.331676</td>\n",
       "      <td>0.101366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnimalsBeingDerps</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>Sniflix</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>Animals and Pets</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.259119</td>\n",
       "      <td>0.235161</td>\n",
       "      <td>0.079254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subreddit       Date  User_ID  PageRank  PR_Community  \\\n",
       "0  AnimalsBeingDerps 2022-09-02  Sniflix   0.00018      0.002661   \n",
       "1  AnimalsBeingDerps 2022-07-09  Sniflix   0.00018      0.002661   \n",
       "2  AnimalsBeingDerps 2023-03-26  Sniflix   0.00018      0.002661   \n",
       "3  AnimalsBeingDerps 2023-03-20  Sniflix   0.00018      0.002661   \n",
       "4  AnimalsBeingDerps 2022-08-08  Sniflix   0.00018      0.002661   \n",
       "\n",
       "           Category  Engagement_Score_Subreddit  Engagement_Score_Category  \\\n",
       "0  Animals and Pets                        0.42                       0.42   \n",
       "1  Animals and Pets                        0.42                       0.42   \n",
       "2  Animals and Pets                        0.42                       0.42   \n",
       "3  Animals and Pets                        0.42                       0.42   \n",
       "4  Animals and Pets                        0.42                       0.42   \n",
       "\n",
       "  Last_Interaction_Date  Decay_Factor  Total_Score  Implicit_Score  \n",
       "0            2023-06-22      0.264485     0.240030        0.079254  \n",
       "1            2023-06-22      0.253438     0.230005        0.079254  \n",
       "2            2023-06-22      0.373265     0.338752        0.103489  \n",
       "3            2023-06-22      0.365468     0.331676        0.101366  \n",
       "4            2023-06-22      0.259119     0.235161        0.079254  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.7\n",
    "main_dfs = []\n",
    "for community_idx in range(len(overall_dfs)):\n",
    "    community_df = overall_dfs[community_idx]\n",
    "    community_subreddit_weight = subreddit_weight[community_idx]\n",
    "    community_category_weight = category_weight[community_idx]\n",
    "    implicit_score_df = calculate_implicit_score(community_df, community_subreddit_weight, community_category_weight, alpha)\n",
    "    main_dfs.append(implicit_score_df)\n",
    "main_dfs[9].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
